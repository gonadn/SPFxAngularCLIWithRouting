{"version":3,"sources":["aedoc/Tokenizer.ts"],"names":[],"mappings":";AAAA,4FAA4F;AAC5F,2DAA2D;;AAE3D,mCAA2C;AAC3C,4DAAqD;AAErD;;GAEG;AACH;IAeE,YAAY,IAAY,EAAE,WAAsC;QAC9D,IAAI,CAAC,YAAY,GAAG,WAAW,CAAC;QAChC,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;IAC/C,CAAC;IAEM,SAAS;QACd,MAAM,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,YAAY,CAAC,MAAM,KAAK,CAAC,CAAC,GAAG,SAAS,GAAG,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;IACnG,CAAC;IAEM,QAAQ;QACb,MAAM,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,YAAY,CAAC,MAAM,KAAK,CAAC,CAAC,GAAG,SAAS,GAAG,IAAI,CAAC,YAAY,CAAC,KAAK,EAAE,CAAC;IACxG,CAAC;IAED;;;;;;;;;;;OAWG;IACO,aAAa,CAAC,IAAY;QAClC,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC;YACV,MAAM,CAAC;QACT,CAAC;QACD,MAAM,UAAU,GAAa,2BAAiB,CAAC,oBAAoB,CACjE,IAAI,CAAC,OAAO,CAAC,KAAK,EAAE,EAAE,CAAC,EAAE,aAAa;QACtC,SAAS,CAAC,eAAe,CAAC,CAAC;QAE7B,sDAAsD;QACtD,MAAM,MAAM,GAAY,EAAE,CAAC;QAE3B,GAAG,CAAC,CAAC,IAAI,CAAC,GAAW,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YACnD,IAAI,KAAY,CAAC;YACjB,MAAM,SAAS,GAAW,UAAU,CAAC,CAAC,CAAC,CAAC;YACxC,MAAM,OAAO,GAAW,SAAS,CAAC,OAAO,CAAC,MAAM,EAAE,GAAG,CAAC,CAAC,IAAI,EAAE,CAAC;YAC9D,EAAE,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;gBAC9B,KAAK,GAAG,IAAI,eAAK,CAAC,iBAAS,CAAC,QAAQ,EAAE,OAAO,CAAC,CAAC;YACjD,CAAC;YAAC,IAAI,CAAC,EAAE,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,GAAG,IAAI,OAAO,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,GAAG,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;gBACnF,KAAK,GAAG,IAAI,CAAC,eAAe,CAAC,OAAO,CAAC,CAAC,CAAC,6CAA6C;YACtF,CAAC;YAAC,IAAI,CAAC,EAAE,CAAC,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,CAAC;gBAC5B,sDAAsD;gBACtD,KAAK,GAAG,IAAI,eAAK,CAAC,iBAAS,CAAC,IAAI,EAAE,EAAE,EAAE,SAAS,CAAC,CAAC;YACnD,CAAC;YAED,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;gBACV,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YACrB,CAAC;QACH,CAAC;QAED,MAAM,CAAC,MAAM,CAAC;IAChB,CAAC;IAED;;;OAGG;IACO,eAAe,CAAC,QAAgB;QACxC,EAAE,CAAC,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,GAAG,IAAI,QAAQ,CAAC,MAAM,CAAC,QAAQ,CAAC,MAAM,GAAG,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;YAC/E,oFAAoF;YACpF,IAAI,CAAC,YAAY,CAAC,8CAA8C,CAAC,CAAC;QACpE,CAAC;QACD,MAAM,YAAY,GAAW,QAAQ,CAAC,KAAK,CAAC,CAAC,EAAE,QAAQ,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QAE3E,EAAE,CAAC,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;YACnC,sFAAsF;YACtF,IAAI,CAAC,YAAY,CAAC,wCAAwC,CAAC,CAAC;YAC5D,MAAM,CAAC;QACT,CAAC;QAED,MAAM,oBAAoB,GAAW,oBAAoB,CAAC;QAC1D,EAAE,CAAC,CAAC,oBAAoB,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;YAC5C,IAAI,CAAC,YAAY,CAAC,oEAAoE;gBACpF,gDAAgD,CAAC,CAAC;YACpD,MAAM,CAAC;QACT,CAAC;QAED,+CAA+C;QAC/C,8FAA8F;QAC9F,MAAM,WAAW,GAAa,YAAY,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC;QAC1D,EAAE,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,KAAK,OAAO,CAAC,CAAC,CAAC;YAC/B,EAAE,CAAC,CAAC,WAAW,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC;gBAC3B,IAAI,CAAC,YAAY,CAAC,0DAA0D,CAAC,CAAC;gBAC9E,MAAM,CAAC;YACT,CAAC;YAED,WAAW,CAAC,KAAK,EAAE,CAAC,CAAC,sBAAsB;YAC3C,MAAM,KAAK,GAAU,IAAI,eAAK,CAAC,iBAAS,CAAC,SAAS,EAAE,OAAO,EAAE,WAAW,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;YACpF,MAAM,CAAC,KAAK,CAAC;QACf,CAAC;QAAC,IAAI,CAAC,EAAE,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,KAAK,aAAa,CAAC,CAAC,CAAC;YAC5C,WAAW,CAAC,KAAK,EAAE,CAAC,CAAC,4BAA4B;YACjD,MAAM,KAAK,GAAU,IAAI,eAAK,CAAC,iBAAS,CAAC,SAAS,EAAE,aAAa,EAAE,WAAW,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;YAC1F,MAAM,CAAC,KAAK,CAAC;QACf,CAAC;QAED,wBAAwB;QACxB,IAAI,CAAC,YAAY,CAAC,mCAAmC,CAAC,CAAC;QACvD,MAAM,CAAC;IACT,CAAC;;AAnHD;;;GAGG;AACY,yBAAe,GAAW,sDAAsD,CAAC;AANlG,4BAsHC","file":"aedoc/Tokenizer.js","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT license.\r\n// See LICENSE in the project root for license information.\r\n\r\nimport Token, { TokenType } from './Token';\r\nimport TypeScriptHelpers from '../TypeScriptHelpers';\r\n\r\n/**\r\n * Handles the tokenization of an AEDoc comment.\r\n */\r\nexport default class Tokenizer {\r\n\r\n  /**\r\n   * Match AEDoc block tags and inline tags\r\n   * Example \"@a @b@c d@e @f {whatever} {@link a} { @something } \\@g\" => [\"@a\", \"@f\", \"{@link a}\", \"{ @something }\"]\r\n   */\r\n  private static _aedocTagsRegex: RegExp = /{\\s*@(\\\\{|\\\\}|[^{}])*}|(?:^|\\s)(\\@[a-z_]+)(?=\\s|$)/gi;\r\n\r\n  /**\r\n   * List of Tokens that have been tokenized.\r\n   */\r\n  private _tokenStream: Token[];\r\n\r\n  private _reportError: (message: string) => void;\r\n\r\n  constructor(docs: string, reportError: (message: string) => void) {\r\n    this._reportError = reportError;\r\n    this._tokenStream = this._tokenizeDocs(docs);\r\n  }\r\n\r\n  public peekToken(): Token {\r\n    return (!this._tokenStream || this._tokenStream.length === 0) ? undefined : this._tokenStream[0];\r\n  }\r\n\r\n  public getToken(): Token {\r\n    return (!this._tokenStream || this._tokenStream.length === 0) ? undefined : this._tokenStream.shift();\r\n  }\r\n\r\n  /**\r\n   * Converts a doc comment string into an array of Tokens. This processing is done so that docs\r\n   * can be processed more strictly.\r\n   * Example: \"This is an AEDoc description with a {@link URL} and more text. \\@remarks example \\@public\"\r\n   * => [\r\n   *  {tokenType: 'text', parameter: 'This is an AEDoc description with a'},\r\n   *  {tokenType: '@link', parameter: 'URL'},\r\n   *  {tokenType: '\\@remarks', parameter: ''},\r\n   *  {tokenType: 'text', parameter: 'example'},\r\n   *  {tokenType: '\\@public', parameter: ''}\r\n   * ]\r\n   */\r\n  protected _tokenizeDocs(docs: string): Token[] {\r\n    if (!docs) {\r\n      return;\r\n    }\r\n    const docEntries: string[] = TypeScriptHelpers.splitStringWithRegEx(\r\n      docs.replace(/\\r/g, ''), // CRLF -> LF\r\n      Tokenizer._aedocTagsRegex);\r\n\r\n    // process each sanitized doc string to a Token object\r\n    const tokens: Token[] = [];\r\n\r\n    for (let i: number = 0; i < docEntries.length; i++) {\r\n      let token: Token;\r\n      const untrimmed: string = docEntries[i];\r\n      const trimmed: string = untrimmed.replace(/\\s+/g, ' ').trim();\r\n      if (trimmed.charAt(0) === '@') {\r\n        token = new Token(TokenType.BlockTag, trimmed);\r\n      } else if (trimmed.charAt(0) === '{' && trimmed.charAt(trimmed.length - 1) === '}') {\r\n        token = this._tokenizeInline(trimmed); // Can return undefined if invalid inline tag\r\n      } else if (untrimmed.length) {\r\n        // If it's not a tag, pass through the untrimmed text.\r\n        token = new Token(TokenType.Text, '', untrimmed);\r\n      }\r\n\r\n      if (token) {\r\n        tokens.push(token);\r\n      }\r\n    }\r\n\r\n    return tokens;\r\n  }\r\n\r\n  /**\r\n   * Parse an inline tag and returns the Token for it if itis a valid inline tag.\r\n   * Example '{@link https://bing.com | Bing}' => '{type: 'Inline', tag: '@link', text: 'https://bing.com  | Bing'}'\r\n   */\r\n  protected _tokenizeInline(docEntry: string): Token {\r\n    if (docEntry.charAt(0) !== '{' || docEntry.charAt(docEntry.length - 1) !== '}') {\r\n      // This is a program bug, since _tokenizeDocs() checks this condition before calling\r\n      this._reportError('The AEDoc tag is not enclosed in \"{\" and \"}\"');\r\n    }\r\n    const tokenContent: string = docEntry.slice(1, docEntry.length - 1).trim();\r\n\r\n    if (tokenContent.charAt(0) !== '@') {\r\n      // This is a program bug, since it should have already been validated by the Tokenizer\r\n      this._reportError('The AEDoc tag does not start with \"@\".');\r\n      return;\r\n    }\r\n\r\n    const unescapedCurlyBraces: RegExp = /([^\\\\])({|}[^$])/gi;\r\n    if (unescapedCurlyBraces.test(tokenContent)) {\r\n      this._reportError(`An unescaped \"{\" or \"}\" character was found inside an inline tag. ` +\r\n        'Use a backslash (\"\\\\\") to escape curly braces.');\r\n      return;\r\n    }\r\n\r\n    // Split the inline tag content with whitespace\r\n    // Example: '@link    https://bing.com  |  Bing' => ['@link', 'https://bing.com', '|', 'Bing']\r\n    const tokenChunks: string[] = tokenContent.split(/\\s+/gi);\r\n    if (tokenChunks[0] === '@link') {\r\n      if (tokenChunks.length < 2) {\r\n        this._reportError('The {@link} tag must include a URL or API item reference');\r\n        return;\r\n      }\r\n\r\n      tokenChunks.shift(); // Gets rid of '@link'\r\n      const token: Token = new Token(TokenType.InlineTag, '@link', tokenChunks.join(' '));\r\n      return token;\r\n    } else if (tokenChunks[0] === '@inheritdoc') {\r\n      tokenChunks.shift(); // Gets rid of '@inheritdoc'\r\n      const token: Token = new Token(TokenType.InlineTag, '@inheritdoc', tokenChunks.join(' '));\r\n      return token;\r\n    }\r\n\r\n    // This is a program bug\r\n    this._reportError('Invalid call to _tokenizeInline()');\r\n    return;\r\n  }\r\n}\r\n"],"sourceRoot":"..\\..\\src"}